\subsubsection{Estructuras de Datos}
\par Como ya se mencion\'o en~\nameref{grafo:estructuras}, ya contamos en el grafo
    de entrada con listas/vectores de adyacencias y una matriz de adyacencias.

\par Al igual que en la heur\'istica golosa y el algoritmo exacto, decidimos
    modelar las cliques con vectores%
    \footnote{\url{http://www.cplusplus.com/reference/vector/vector/}}.

\par A su vez, para mejorar la eficiencia al recorrer la vecindad, se
    utilizan un vector/clique como \emph{min heaps} seg\'un el grado
    de los nodos, permitiendonos acceder en $\mathcal O(1)$ al nodo
    de menor grado. Los motivos de este proceder se detallan en
    la siguiente secci\'on.

\subsubsection{Pseudoc\'odigo de complejidad}
\par Se presenta a continuaci\'on un pseudoc\'odigo m\'as espec\'ifico de la implementaci\'on
    de este algoritmo provista junto con este trabajo. El mismo tiene en cuenta
    las estructuras de datos explicadas en el punto anterior.

\par Luego del pseudoc\'odigo se justifican detalladamente las complejidades
    expuestas a continuaci\'on que no sean evidentes\footnote{Consideramos
    como "complejidades evidentes" las asignaciones de variables, operaciones
    m\'atematicas simples, asignaciones/inicializaci\'on de posiciones de
    un vector/\emph{deque} o cualquier contenedor de acceso aleatorio/arbitrario}.

\par Debemos aclarar, debido a las variantes ya presentadas sobre esta
    heur\'istica, que el siguiente an\'alisis de complejidad aplica
    sobre la heur\'istica que selecciona al primer vecino v\'alido encontrado,
    en una vecindad donde s\'olo se consideran las cliques con un nodo m\'as
    o un nodo menos y que selecciona como clique inicial a alg\'un nodo
    de grado mayor o igual al grado promedio del grafo.

\par El an\'alisis de complejidad de las variantes se realiza en la secci\'on
    \ref{bl:compl:variantes}.

\bigskip

\begin{pseudocodigo}[Heur\'istica de B\'usqueda Local para \emph{CMF} - Complejidad]
    \Require Un grafo $G$ con $n$ v\'ertices numerados de $1$ a $n$ y $m$ aristas. El mismo
        cuenta con las siguientes estructuras de datos que lo modelan:
        \begin{itemize}
            \item Vectores de adyacencia: Dado un vertice $v$, $vecinos(v)$ nos da todos los
                nodos adyacentes a $v$ en $G$.

            \item Matriz de adyacencia: Dados los v\'ertices $v$ y $w$, $adyacentes(v,w)$ y
                $adyacentes(w,v)$ nos devuelven $true$ si y s\'olo si $v$ es adyacente
                a $w$ en $G$.

            \item Vector de nodos de $G$.
        \end{itemize}
    \Ensure\Statex
        \begin{itemize}
            \item Un vector $K$ correspondiente a la \emph{clique} de m\'axima frontera
                encontrada por la heur\'istica.

            \item El cardinal de $\delta(K)$, siendo $K$ la \emph{clique} del item anterior.
        \end{itemize}
    \Statex
    \State $K \gets \emptyset$ \Compl{Brown}{}{$n$}{}
    \If{$m = \frac{n(n-1)}{2}$} \Compl{Blue}{}{$1$}{}
        \State $K \gets \left\{1;\dots;\left\lfloor\sfrac{n}{2}\right\rfloor\right\}$ \Compl{Blue}{}{$n$}{}
        \State $\delta_{max} \gets \left\lfloor\sfrac{n}{2}\right\rfloor\cdot
            \left\lceil\sfrac{n}{2}\right\rceil$ \Compl{Blue}{}{$1$}{}
        \Statex
    \Else
        \State $K \gets$ Primer nodo de grado mayor o igual al grado promedio \Compl{Blue}{}{$n$}{}
        \State $\delta(K) \gets d(top(K))$ \Compl{Blue}{}{$1$}{}
        \If{$\exists v \in vecinos(top(K))$ tal que $d(v) > 2|K|$} \Compl{Red}{}{$n$}{}
            \State $v_{add} \gets v$ \Compl{Red}{}{$1$}{}
            \State $\delta(K+v_{add}) \gets \delta(K) + d(v_{add}) - 2|K|$ \Compl{Red}{}{$1$}{}
        \EndIf \Compl{Blue}{Costo del \emph{si}: }{$n$}{}
        \Statex
        \State $v_{rem} \gets top(K)$ \Compl{Blue}{}{$1$}{}
        \State $\delta(K-v_{rem}) \gets \delta(K)-d(v_{rem})+2(|K|-1)$ \Compl{Blue}{}{$1$}{}
        \Statex
        \While{$\delta(K) < \delta(K+v_{add})$ $\lor$ $\delta(K) < \delta(K-v_{rem})$} \Compl{Red}{}{$1$}{}
            \If{$\delta(K+v_{add}) > \delta(K-v_{rem})$} \Compl{Fuchsia}{}{$1$}{}
                \State $push\_heap(K,v_{add})$ \Compl{Fuchsia}{}{$log(n)$}{}
                \State $\delta(K) \gets \delta(K+v_{add})$ \Compl{Fuchsia}{}{$1$}{}
                \Statex
            \Else
                \State $pop\_heap(K)$ \Compl{Fuchsia}{}{$log(n)$}{}
                \State $\delta(K) \gets \delta(K-v_{rem})$ \Compl{Fuchsia}{}{$1$}{}
                \Statex
            \EndIf \Compl{Red}{Costo del \emph{si}: }{$log(n)$}{}
            \Statex
            \Statex $\triangleright$ Ya salte a un vecino, recorro la nueva vecindad
            \If{$\exists v \in candidatos(K)$ tal que $d(v) > 2|K|$} \Compl{Fuchsia}{}{$n^2$}{}
                \State $v_{add} \gets v$ \Compl{Fuchsia}{}{$1$}{}
                \State $\delta(K+v_{add}) \gets \delta(K) + d(v_{add}) - 2|K|$ \Compl{Fuchsia}{}{$1$}{}
            \EndIf \Compl{Red}{Costo del \emph{si}: }{$n^2$}{}
            \Statex
            \State $v_{rem} \gets top(K)$ \Compl{Red}{}{$1$}{}
            \State $\delta(K-v_{rem}) \gets \delta(K)-d(v_{rem})+2(|K|-1)$ \Compl{Red}{}{$1$}{}
            \Statex
        \EndWhile \Compl{Blue}{Costo del \emph{mientras}: }{$n^2$}{veces $\times$ $\mathcal O(n^2 + log(n)) = \mathcal O(n^4)$ }
    \EndIf \Compl{Brown}{Costo del \emph{si}: }{$n^4 + n$}{$= \mathcal O(n^4)$ }
    \State \Return{$\delta(K)$, $K$} \Compl{Brown}{}{$1$\label{bl:return}}{}
    \Statex
    \Statex \Compl{Brown}{Costo Total de la Heur\'istica: }{$n^4 +n$}{$= \mathcal O(n^4)$ }
\end{pseudocodigo}

\bigskip

\par La primera parte del algoritmo es exactamente igual a la de la
    heur\'istica golosa y el algoritmo exacto: reconoce en $\mathcal O(1)$
    si el grafo $G$ es un $K_n$ y en caso afirmativo, devuelve
    la \emph{CMF} con costo lineal. Esto ya fue justificado en
    los dos casos previos, as\'i pues se omite su justificaci\'on.

\par Luego, en caso de estar ante un $G$ que no es un grafo completo,
    el algoritmo busca a un nodo que tenga grado mayor o igual al
    promedio. Esta b\'usqueda se realiza sobre el vector de nodos
    (los cuales permiten el acceso a su grado en $\mathcal O(1)$),
    con lo cual el costo en el peor caso pasa a ser revisar
    todos los nodos del grafo\footnote{\url{http://www.cplusplus.com/reference/algorithm/find_if/}},
    siendo la complejidad entonces $\mathcal O(n)$. Habiendo
    escogido el nodo/clique inicial, se guarda la frontera
    parcial correspondiente (que no es otra cosa que el grado
    de dicho nodo, que como se dijo, es accedible en tiempo
    constante) y se asigna dicho nodo al vector que representa
    la clique (lo cual tiene un costo constante tambien\footnote{%
    \url{http://www.cplusplus.com/reference/vector/vector/push_back/}}.

\par Luego, antes de comenzar el ciclo, se inicializan los posibles
    valores de la vecindad. En s\'i mismo, se recorrer la vecindad
    \emph{inicial}, guardando las primeras cliques vecinas (una
    con un nodo m\'as y otra con un nodo menos\footnote{Esta \'ultima
    clique es trivial ya que en este momento la clique se compone
    de s\'olo un nodo.}) que incrementen la funci\'on objetivo.

\par Buscar una clique que incremente la frontera es lineal ya
    que basta con recorrer el \emph{deque} de vecinos del
    \'unico nodo de la clique (el cual es accesible en tiempo
    constante gracias a el vector de nodos de la estructura del
    grafo y a la propia estructura de estos nodos\footnote{Ver
    \emph{\nameref{grafo:estructuras}}, en la secci\'on
    \emph{\nameref{notas_preliminares}}.} y realizar una
    \'unica comparacion de tiempo constante (verificar que
    efectivamente su grado incrementa la frontera).

\par Encontrado este nodo, calcular cuanto incrementa la funci\'on
    es trivial y se realiza en tiempo constante, ya que alcanza
    con hacer las operaciones matem\'aticas sobre la frontera
    de la clique actual y el grado del nodo que se a\~nadir\'ia%
    \footnote{Ver la Secci\'on \emph{\nameref{notas:calc_front}},
    en \emph{\nameref{notas_preliminares}}.}.

\par Luego, para encontrar un nodo que incremente la frontera
    si fuese eliminado de la clique se hace aprovechando
    las estructuras de un \emph{min heap} sobre los grados
    de la clique, utilizando la representaci\'on de este
    que no es otra que un vector \footnote{\url{%
    http://www.cplusplus.com/reference/algorithm/make_heap/}}.
    Si bien el heap en este caso no fue inicializado mediante
    la funci\'on \emph{make\_heap}, esto no es necesario ya
    que en esta variante, s\'olo se tiene un nodo en la clique.
    Luego, si mantenemos esta estructura en el vector, las operaciones
    $push\_heap$ y $pop_heap$ tendr\'an un coste logar\'itmico
    mientras que $top$ sera de coste constante\footnote{%
    \url{http://www.cplusplus.com/reference/algorithm/push_heap/},%
    \url{http://www.cplusplus.com/reference/algorithm/pop_heap/},%
    \url{http://www.cplusplus.com/reference/vector/vector/front/},%
    \url{http://www.cplusplus.com/reference/vector/vector/pop_back/},%
    \url{http://www.cplusplus.com/reference/vector/vector/push_back/}}.

\par Teniendo ya un \emph{min heap}, podemos acceder al nodo
    de menor grado de la clique actual en $\mathcal O(1)$

\par Nuevamente, calcular la frontera si se quitase dicho
    nodo es trivial. Pero ac\'a debemos justificar el hecho
    de no buscar alg\'un otro nodo que al ser quitado incremente
    la frontera en caso de que este nodo (el tope del heap) no
    lo haga. El fundamento aqu\'i es que el tope del heap
    es el nodo de menor grado, por lo tanto, es el nodo
    que menos frontera le a\~nade a $K$, por lo tanto,
    quitar cualquier otro nodo implicar\'ia quitar un nodo
    de mayor grado, lo que significa que estar\'iamos
    considerando quitar un nodo que aporta m\'as frontera
    que el tope del heap y por lo tanto estariamos
    obteniendo una frontera menor que la que se obtiene
    de quitar el tope. Esto nos permite asegurar que si
    se tiene el nodo de menor grado de la clique, y este
    no incrementa la frontera si se quitase de la clique,
    entonces ning\'un otro nodo de la clique lo har\'a.

\par Luego, comienza el ciclo de la b\'usqueda local. En la
    guarda del mismo se realizan s\'olo comparaciones
    de enteros que son almacenados en variables de la implementaci\'on
    de esta funci\'on de \emph{C++}, por lo cual su acceso
    tiene un coste $\mathcal O(1)$.

\par Inmediatamente al comenzar el ciclo hay un condicional
    \emph{si}. El mismo en su guarda realiza una operaci\'on
    $\mathcal O(1)$ por los mismos motivos explicados en
    el p\'arrafo anterior. Dentro de sus dos ramas vemos
    que se realizan 1 asignaci\'on ($\mathcal O(1)$) y
    un $push\_heap$ o $pop\_heap$, que tienen un coste
    logar\'itmico como ya se explico m\'as arriba.

\par En la segunda mitad del ciclo, se
    revisa la nueva vecindad (en este punto, el ciclo
    habr\'a a\~nadido o quitado alg\'un nodo de la
    clique, por lo cual tenemos una nueva vecindad). En
    el caso de los vecinos que se componen de cliques con
    un nodo menos, el proceso es id\'entico al realizado
    antes de entrar al ciclo, con lo cual no hace falta
    justificar nada m\'as. En cuanto a las cliques que
    contienen un nodo m\'as, ahora tenemos una clique
    con (posiblemente) m\'as de un nodo, por lo cual,
    debemos ver todos sus candidatos, pero no nos podemos
    basar en los nodos de la clique antes de realizar
    el salto al vecino pues si se quito un nodo, los
    candidatos podr\'ian incrementarse. Por lo tanto,
    debemos recorrer (en el peor de los casos) todos
    los nodos adyacentes a alg\'un nodo de la clique
    (que son accesibles en $\mathcal O(1)$ gracias al vector
    de nodos de la estructura de $G$) y verificar 2
    cosas: que sean adyacentes a todos los dem\'as
    nodos de la clique y que incrementen la frontera%
    \footnote{Es decir, que $d(v) > 2|K|$.}. En caso
    de encontrar uno, podemos detener este recorrido de posibles
    nodos candidatos, ya que no estamos buscando saltar
    al mejor vecino sino al primero que encontremos
    que cumpla con nuestros requerimientos. Pero a\'un as\'i,
    en el peor de los casos deberemos recorrerlos a todos,
    es decir, $\mathcal O(n)$ nodos adyacentes, y tambi\'en
    como cota para $|K|$ debemos considerar que podr\'ia
    estar en el orden de $\mathcal O(n)$ elementos, siendo
    el costo de esta b\'usqueda de vecino candidato
    con un nodo m\'as, igual a $\mathcal O(n^2)$.

\par Por \'ultimo, ya teniendo calculado el coste del ciclo,
    debemos acotar la cantidad de iteraciones que tendr\'a.
    Esto es d\'ificil, ya que sin mayor informaci\'on sobre
    el grafo de entrada y su estructura, no se puede saber
    a ciencia cierta cuantas veces podr\'a "deplazarse" el
    algoritmo en la vecindad definida. Por lo tanto, se
    decidi\'o acotar mediante lo m\'inimo que crece la frontera
    entre iteraci\'on e iteraci\'on. Este m\'inimo es, simplemente,
    1. Considerando este peor caso, donde la funci\'on objetivo
    crece muy lentamente, y considerando que la frontera m\'axima
    no puede ser mayor a $m$ (ya que no hay m\'as aristas que $m$
    en $G$), podemos asegurar que la cantidad de iteraciones
    que har\'a el ciclo estar\'a acotada por $m$, y $m$ est\'a
    acotado por $n^2$.

\par Por lo tanto, sabiendo ya que el costo por ciclo es
    $\mathcal O(n^2)$, y sabieno que no tendremos m\'as
    de $n^2$ iteraciones, conclu\'imos que el costo del
    ciclo estar\'a acotado por $\mathcal O(n^4)$.

\par Al final de la heur\'istica, se devuelven la frontera
    ($\mathcal O(1)$ por ser un tipo primitivo del lenguaje)
    y la clique ($\mathcal O(1)$ por ser devuelta por
    referencia). Entonces, el coste final de todo el algoritmo
    heur\'istico recae sobre el ciclo y la inicializaci\'on
    mediante \emph{reserve}\footnote{\url{%
    http://www.cplusplus.com/reference/vector/vector/reserve/}} de
    $K$. Finalmente, el coste es $\mathcal O(n + n^4)$, que
    asint\'oticamente hablando es $\mathcal O(n^4)$.

\subsubsection{Complejidad de las Variantes\label{bl:compl:variantes}}
\par Para esta heur\'istica se han presentado numerosas variantes, que
    a su vez pueden ser combinadas para conseguir m\'as variantes. En
    particular, en la Secci\'on \ref{bl:compl:variantes} se presentaron
    3 par\'ametros con 2 variantes:

\begin{enumerate}
    \item \textbf{Vecindad} tenemos dos opciones, una vecindad de cliques
        que tengan un nodo m\'as o uno menos que la clique actual o
        una extensi\'on de esta definici\'on que incluye a las cliques
        que tienen la misma cantidad de nodos pero uno distinto.

    \item \textbf{Clique Inicial} podemos empezar con alg\'un nodo
        de grado mayor o igual al promedio o una clique encontrada
        por la heur\'istica golosa.

    \item \textbf{Primer/Mejor Vecino} al recorrer la vecindad decidimos
        quedarnos con el primer vecino que encontramos que mejora
        la funci\'on objetivo o con el vecino que maximiza esta mejora
        (en caso de existir varios vecinos que la mejoren).
\end{enumerate}

\bigskip

\par Tan solo observando estas opciones, se puede ver que existen 8
    variantes distintas.

\par En el an\'alisis de complejidad ya expuesto se analiz\'o una versi\'on
    donde se selecciona al \textbf{primer vecino}, donde se comienza
    con un \textbf{nodo de al menos grado promedio} como clique inicial y
    con una vecindad de \textbf{cliques con un nodo m\'as o uno menos}. En
    dicho an\'alisis concluimos que la complejidad asint\'otica temporal
    es $\mathcal O(n^4)$

\par Sin necesidad de presentar 8 pseudoc\'odigos de complejidad, podemos
    analizar la complejidad de las variantes a partir de este resultado.

\par En el caso de utilizar como clique inicial el resultado de la
    heur\'istica golosa, se nos sumar\'ia a la complejidad ya calculada
    el costo de la heur\'istica ($\mathcal O(n^2)$), m\'as la inicializaci\'on
    de la frontera inicial que luego se va actualizando a medida que la b\'usqueda
    local se mueve entre los vecinos. Para calcular esta frontera, alcanza
    con recorrer el vector/clique pasado por la heur\'istica golosa y calcular
    la frontera como ya se explic\'o en las \emph{\nameref{notas_preliminares},
    \nameref{notas:calc_front}}. Como el acceso a los grados de los nodos
    es constante gracias a la estructura del grafo (vector de nodos), el
    costo de este calculo esta acotado por la cantidad de nodos de la
    clique que nos da la heur\'istica golosa: $\mathcal O(n)$. Por \'ultimo,
    en nuestra implementaci\'on se utiliza un \emph{min heap}. En la versi\'on
    inicial no nos preocupamos por inicializarlo ya que comienza con un \'unico
    nodo, pero ahora tenemos la clique provista por la heur\'istica, por lo
    cual debemos realizar una llamada a $make\_heap$\footnote{\url{%
    http://www.cplusplus.com/reference/algorithm/make_heap/}} que tiene un
    costo tambi\'en lineal.

\par Nos queda entonces como complejidad para las variantes con la heur\'istica golosa:

\bigskip
\par $\underbrace{\mathcal O(n^4)}_{\text{Costo B\'usqueda Local}} +
    \underbrace{\mathcal O(n^2)}_{\text{Costo Golosa}} +
    \underbrace{\mathcal O(n)}_{\text{Costo extra de calculo de Frontera}} +
    \underbrace{\mathcal O(n)}_{\text{Costo $make\_heap$}}
    = \mathcal O(n^4)$
\bigskip

\par Vemos entonces, que utilizar como entrada el resultado de la heur\'istica
    golosa no afecta a nuestra complejidad asint\'otica.

\par Luego, tenemos la variante del \textbf{mejor vecino}. Para implementar
    esta de manera c\'omoda, se decidi\'o ordenar las listas/vectores
    de adyacencia de la estructura interna del grafo\footnote{Seccion
    \emph{\nameref{grafo:estructuras}, \nameref{notas_preliminares}}}
    seg\'un el grado de estos, de mayor a menor. De esta manera, ya que
    siempre recorrermos las listas de adyacencia y los vectores siguiendo
    este nuevo orden, al encontrar un nodo que sirva a los prop\'ositos
    de la heur\'istica, este seguro ser\'a la mejor opci\'on. En el caso
    de agregar un nodo, habremos encontrado al nodo de mayor grado
    que podemos agregar, y como ya se a explicado en este documento,
    este sumar\'a m\'as a la frontera que cualquier nodo de menor grado
    (ya que las aristas de la frontera que se pierden al agregar un nodo
    se mantienen constantes para todos los posibles nodos candidatos a
    a\~nadirse). Y, en el caso de quitar un nodo, en realidad ya est\'abamos
    trabajando con la mejor opci\'on al utilizar un \emph{min heap}. Esto
    se hizo as\'i pues era m\'as barato (en complejidad asint\'otica temporal)
    que tener que recorrer todos los nodos de la clique y buscar a un
    nodo que al eliminarse incrementase la frontera (que hubiese tenido
    un coste $\mathcal O(n)$).

\par Por lo tanto, debemos tener en cuenta la nueva complejidad de instanciaci\'on
    de las estructuras del grafo. Como ya se mencion\'o en la Secci\'on
    \emph{\nameref{notas_preliminares}},
    este costo pasa a ser $\mathcal O(n^2\cdot log(n))$. Entonces la complejidad
    de la variante quedar\'ia expresada (para la variante con la heur\'istica golosa
    tambi\'en, ya que la complejidad del ordenamiento es superior a la complejidad
    de la heur\'istica) como:

\bigskip
\par $\underbrace{\mathcal O(n^4)}_{\text{Costo B\'usqueda Local}} +
    \underbrace{\mathcal O(n^2\cdot log(n))}_{\text{Costo Ordenamientos}} =
    \mathcal O(n^4)$
\bigskip

\par Por \'ultimo, nos queda ver las variantes donde extendemos la vecindad. Para este
    caso s\'i se decidi\'o presentar un pseudoc\'odigo de complejidad dada la complejidad
    para recorrer la nueva vecidad. Se presenta el mismo a continuaci\'on para las variantes
    de \textbf{nodo de al menos grado promedio} y \textbf{primer vecino}.

\bigskip

\begin{pseudocodigo}[Heur\'istica de B\'usqueda Local para \emph{CMF} con Intercambio - Complejidad]
    \Require Un grafo $G$ con $n$ v\'ertices numerados de $1$ a $n$ y $m$ aristas. El mismo
        cuenta con las siguientes estructuras de datos que lo modelan:
        \begin{itemize}
            \item Vectores de adyacencia: Dado un vertice $v$, $vecinos(v)$ nos da todos los
                nodos adyacentes a $v$ en $G$.

            \item Matriz de adyacencia: Dados los v\'ertices $v$ y $w$, $adyacentes(v,w)$ y
                $adyacentes(w,v)$ nos devuelven $true$ si y s\'olo si $v$ es adyacente
                a $w$ en $G$.

            \item Vector de nodos de $G$.
        \end{itemize}
    \Ensure\Statex
        \begin{itemize}
            \item Un vector $K$ correspondiente a la \emph{clique} de m\'axima frontera
                encontrada por la heur\'istica.

            \item El cardinal de $\delta(K)$, siendo $K$ la \emph{clique} del item anterior.
        \end{itemize}
    \Statex
    \State $K \gets \emptyset$ \Compl{Brown}{}{$n$}{}
    \If{$m = \frac{n(n-1)}{2}$} \Compl{Blue}{}{$1$}{}
        \State $K \gets \left\{1;\dots;\left\lfloor\sfrac{n}{2}\right\rfloor\right\}$ \Compl{Blue}{}{$n$}{}
        \State $\delta_{max} \gets \left\lfloor\sfrac{n}{2}\right\rfloor\cdot
            \left\lceil\sfrac{n}{2}\right\rceil$ \Compl{Blue}{}{$1$}{}
        \Statex
    \Else
        \State $K \gets$ Primer nodo de grado mayor o igual al grado promedio \Compl{Blue}{}{$n$}{}
        \State $\delta(K) \gets d(top(K))$ \Compl{Blue}{}{$1$}{}
        \If{$\exists v \in vecinos(top(K))$ tal que $d(v) > 2|K|$} \Compl{Red}{}{$n$}{}
            \State $v_{add} \gets v$ \Compl{Red}{}{$1$}{}
            \State $\delta(K+v_{add}) \gets \delta(K) + d(v_{add}) - 2|K|$ \Compl{Red}{}{$1$}{}
        \EndIf \Compl{Blue}{Costo del \emph{si}: }{$n$}{}
        \Statex
        \State $v_{rem} \gets top(K)$ \Compl{Blue}{}{$1$}{}
        \State $\delta(K-v_{rem}) \gets \delta(K)-d(v_{rem})+2(|K|-1)$ \Compl{Blue}{}{$1$}{}
        \Statex
        \State Busco $v_{exchIN}$ y $v_{exchOUT}$ tales que $\delta(K) < \delta(K-v_{exchOUT}+v_{exchIN})$ \Compl{Blue}{}{$n^3$}{}
        \State $\delta(K-v_{exchOUT}+v_{exchIN}) \gets \delta(K) - d(v_{exchOUT}) + d(v_{exchIN})$ \Compl{Blue}{}{$1$}{}
        \Statex
        \While{%
        $\begin{pmatrix}
            \text{\Huge{$\bigvee$}} &
            \begin{matrix}
                \delta(K) < \delta(K+v_{add})\\
                \delta(K) < \delta(K-v_{rem})\\
                \delta(K) < \delta(K-v_{exchOUT}+v_{exchIN})
            \end{matrix}
        \end{pmatrix}$%
        } \Compl{Red}{}{$1$}{}
            \Statex
            \If{$\delta(K+v_{add}) > \delta(K-v_{rem})$ $\land$ $\delta(K+v_{add}) > \delta(K-v_{exchOUT}+v_{exchIN})$} \Compl{Fuchsia}{}{$1$}{}
                \State $push\_heap(K,v_{add})$ \Compl{Fuchsia}{}{$log(n)$}{}
                \State $\delta(K) \gets \delta(K+v_{add})$ \Compl{Fuchsia}{}{$1$}{}
                \Statex
            \ElsIf{$\delta(K-v_{rem}) > \delta(K-v_{exchOUT}+v_{exchIN})$} \Compl{Fuchsia}{}{$1$}{}
                \State $pop\_heap(K)$ \Compl{Fuchsia}{}{$log(n)$}{}
                \State $\delta(K) \gets \delta(K-v_{rem})$ \Compl{Fuchsia}{}{$1$}{}
                \Statex
            \Else
                \State Intercambio en $K$ los nodos $v_{exchOUT}$ y $v_{exchIN}$ \Compl{Fuchsia}{}{$1$}{}
                \State Mantengo la estructura del \emph{heap} \Compl{Fuchsia}{}{$log(n)$}{}
                \State $\delta(K) \gets \delta(K) - d(v_{exchOUT}) + d(v_{exchIN})$ \Compl{Fuchsia}{}{$1$}{}
            \EndIf \Compl{Red}{Costo del \emph{si}: }{$log(n)$}{}
            \Statex
            \Statex $\triangleright$ Ya salte a un vecino, recorro la nueva vecindad
            \If{$\exists v \in candidatos(K)$ tal que $d(v) > 2|K|$\label{bl:candidatos}} \Compl{Fuchsia}{}{$n^2$}{}
                \State $v_{add} \gets v$ \Compl{Fuchsia}{}{$1$}{}
                \State $\delta(K+v_{add}) \gets \delta(K) + d(v_{add}) - 2|K|$ \Compl{Fuchsia}{}{$1$}{}
            \EndIf \Compl{Red}{Costo del \emph{si}: }{$n^2$}{}
            \Statex
            \State $v_{rem} \gets top(K)$ \Compl{Red}{}{$1$}{}
            \State $\delta(K-v_{rem}) \gets \delta(K)-d(v_{rem})+2(|K|-1)$ \Compl{Red}{}{$1$}{}
            \Statex
            \State Busco $v_{exchIN}$ y $v_{exchOUT}$ tales que $\delta(K) < \delta(K-v_{exchOUT}+v_{exchIN})$ \Compl{Red}{}{$n^3$}{}
            \State $\delta(K-v_{exchOUT}+v_{exchIN}) \gets \delta(K) - d(v_{exchOUT}) + d(v_{exchIN})$ \Compl{Red}{}{$1$}{}
            \Statex
        \EndWhile \Compl{Blue}{Costo del \emph{mientras}: }{$n^2$}{veces $\times$ $\mathcal O(n^3 + n^2 + log(n)) = \mathcal O(n^5)$ }
    \EndIf \Compl{Brown}{Costo del \emph{si}: }{$n^5 + n$}{$= \mathcal O(n^5)$ }
    \State \Return{$\delta(K)$, $K$} \Compl{Brown}{}{$1$\label{bl:return}}{}
    \Statex
    \Statex \Compl{Brown}{Costo Total de la Heur\'istica: }{$n^5 + n$}{$= \mathcal O(n^5)$ }
\end{pseudocodigo}

\bigskip

\par Para este nuevo pseudoc\'odigo, queda claro que lo nuevo (y lo que quedar\'ia por
    justificar) es el costo de mantener la estructura del heap cuando se intercambia
    un elemento que no fue removido/agregado mediante las funciones $push\_heap$/%
    $pop\_heap$ y el costo encontrar los nodos $v_{exchIN}$ y $v_{exchOUT}$.

\par En el primer caso, para mantener la estructura del \emph{min heap}, la \emph{STL}
    de \emph{C++} no nos provee de un mecanimos para cambiar un nodo arbitrario en
    el vector que mantiene la estructura. Por ende, revisando/releyendo la documentaci\'on
    de la materia \emph{Algoritmos y Estructuras de Datos 2}, se implement\'o
    dicha funcionalidad que nos permite "bajar" (o "subir") un nodo en la estructura
    del \emph{heap} con costo $\mathcal O(log(n))$\footnote{\url{%
    http://dc.uba.ar/materias/aed2/actual/descargas/teoricas/heaps/view}}.

\par En cuanto a la b\'usqueda de los nodos que se podr\'ian intercambiar,
    la idea/problema pasa a ser que si se considera la clique actual del ciclo
    sin un nodo, los candidatos de dicha $K-v$ podr\'ian tener nuevos elementos. Por
    lo tanto, lo que se hizo fue recorrer los nodos de la clique actual ($\mathcal O(n)$ veces) y
    calcular los nodos $candidatos$ de la clique sin el nodo en el cual se est\'a
    parado en el momento ($\mathcal O(n^2)$, tal como ocurre en la l\'inea
    \ref{bl:candidatos}, y cuya complejidad fue explicada en el primer
    pseudoc\'odigo de esta heur\'istica), y a medida que se hace esto,
    ver si cada nodo que se agrega a los candidatos incrementa la frontera de
    $K-v$ lo suficiente para superar la frontera de $K$. Luego, nos quedamos
    con el mejor intercambio\footnote{Es decir, el que m\'as incrementa la
    funci\'on objetivo.} (ya que este proceso se realiza para todos
    los nodos de la clique actual).

\par Por lo tanto, el costo de encontrar el mejor intercambio es, efectivamente,
    $\mathcal O(n)\text{veces} \times \mathcal O(n^2) = \mathcal O(n^3)$.

\par Ya finalizando, se puede ver para las variantes con la heur\'istica golosa
    y los vecinos ordenados que los costos adicionales no superan el costo
    de esta variante con la vecindad extendida ($\mathcal O(n^5)$), por lo tanto,
    usando los mismos fundamentos de las variantes para la vecindad "reducida",
    llegamos a la conclusi\'on de que para las variantes con esta vecindad el
    costo asint\'otico temporal se mantiene en $\mathcal O(n^5)$.
