\subsubsection{Estructuras de Datos}
\par Como ya se coment\'o en las \emph{Notas Preliminares}, las estructuras internas
    elegidas para representar grafos fueron una matriz de adyacencia y listas
    de adyacencia para cada nodo, m\'as un vector de punteros a \emph{nodo}
    que nos da acceso en tiempo constante a los datos del nodo (como su grado en $G$,
    su "id" y su lista de adyacencia).

\par A la hora de resolver el problema dado con nuestro algoritmo de \emph{backtracking},
    fueron necesarias otras estructuras de datos para poder resolver el problema
    lo m\'as eficientemente posible (m\'as all\'a de saber de antemano que la complejidad
    asint\'otica ser\'ia exponencial).

\par Como ya se explic\'o, el algoritmo lo que hace esencialmente es construir las cliques
    del grafo de entrada. Para hacer esto, utiliza tres conjuntos: La clique parcial que
    esta construyendo, los nodos candidatos que se podr\'ian agregar a dicha clique parcial,
    y los nodos candidatos que ya fueron agregados a la clique y para los cuales ya
    se recorri\'o su rama del \emph{backtracking}.

\par Guardar toda esta informaci\'on para todas las cliques no-maximales puede ser engorroso
    y poco eficiente. Por lo cual decidimos implementar ciertas metodolog\'ias para
    no tener que disponer de esta cantidad de datos sobre las instancias parciales
    que ya fueron y son generadas.

\par En primer lugar, como ya se coment\'o durante la explicaci\'on del algoritmo, al ser
    el mismo descripto mediante conjuntos no exist\'ia el riesgo de considerar distintas
    permutaciones del mismo conjunto/clique (justamente, por ser conjuntos no tienen orden
    asociado y por lo tanto no tiene sentido hablar de "permutaciones de los elementos
    de un conjunto"). Pero al pasar a la implementaci\'on, y decidir utilizar estructuras
    que nos permitan resolver el problema de manera eficiente, nos encontramos con que
    el \emph{set}\footnote{\url{http://www.cplusplus.com/reference/set/}} no era la mejor
    elecci\'on (sus complejidades para insertar y eliminar elementos son logar\'itmicas).
    Por lo tanto, decidimos utilizar vectores\footnote{\url{http://www.cplusplus.com/reference/vector/vector/}}
    para representar a las cliques y \emph{deques}\footnote{\url{http://www.cplusplus.com/reference/deque/deque/}}
    para representar a los candidatos de cada clique parcial.

\par Al utilizar estas estructuras nos encontramos
    con el problema de las permutaciones del mismo "conjunto" representado. Para sortear
    este problema decidimos ir eligiendo los nodos de la clique y sus candidatos respetando
    un orden dado (que bien podr\'ia ser los grados de los nodos, su "id" o cualquier orden
    arbitrario). De esta manera, al ir formando una clique, s\'olo tomaremos en cuenta a
    la hora de calcular el conjunto de candidatos a aquellos nodos que sean menores (para
    el orden definido) que el \'ultimo elemento agregado a la clique. Entonces, suponiendo
    que se est\'a construyendo una clique $K\setminus\{v\}$ y el \'ultimo nodo agregado a la misma es $v$,
    todas sus ramificaciones est\'an representadas por los candidatos de $K+v$, una vez
    procesados todos estos, se hace \emph{backtracking} quitando a $v$ de la clique y se
    agrega otro nodo (de las ramificaciones restantes de $K$) a la clique. Llamemos a este
    $v'$. Por lo que comentamos, sabemos que para el orden establecido $v > v'$, pues
    $v$ fue la rama anterior elegida de las posibles ramas de $K$. Ahora tenemos la
    clique $K+v'$, y tenemos una lista de candidatos asociado a ella. Por lo explicado,
    en estas ramificaciones de $K+v'$ no estar\'a $v$, pues $v$ es mayor que el \'ultimo
    nodo agregado a la clique ($v'$).

\par De esta manera evitamos considerar permutaciones de la misma clique. Pues si $v'$
    era una ramificaci\'on v\'alida de $K+v$, en alg\'un momento se habr\'a tenido
    en cuenta $K+v+v'$, y al considerar las ramificaciones de $K+v'$, $v$ seguro
    no estar\'a en sus ramificaciones m\'as all\'a de que cumpla los requerimientos
    para ser un candidato v\'alido para $K+v'$, ya que el orden impuesto es tenido
    en cuenta al calcular los candidatos de una clique. Esto evita las permutaciones ya
    que si no lo tuviesemos en cuenta al orden establecido y $v$ fuese un candidato
    v\'alido de $K+v'$, habr\'iamos considerado las cliques (y sus ramificaciones)
    $K+v+v'$ y $K+v'+v$, que son esencialmente las mismas.

\par En nuestro caso particular, decidimos establecer el orden de mayor a menor
    seg\'un el grado de los nodos. A su vez, mantenemos este orden al calcular
    los candidatos de cada clique parcial. De esta manera, a la hora de calcular
    la cota para la frontera m\'axima de una rama\footnote{Secci\'on
    \ref{backtracking:poda:cota_frontera_max},
    \emph{\nameref{backtracking:poda:cota_frontera_max}}}
    simplemente debemos recorrer la lista de candidatos y detenernos en el primer
    candidato que al ser considerado para a\~nadirse no incremente la frontera
    (esto funciona pues los nodos candidatos siguientes al tener menor grado
    debido al orden establecido seguro que tampoco incrementaran la cota
    de la frontera de la rama). \label{orden_establecido}

\par Habiendo resuelto esto nos queda comentar como resolvemos el otro problema:
    el c\'alculo de los candidatos de una clique parcial $K$ y de los candidatos
    de esta misma clique que ya fueron procesados.

\par En primera instancia, como utilizamos vectores y \emph{deques} para representar
    los conjuntos, llevar un conjunto de los nodos que ya fueron procesados para una
    clique $K$ ser\'ia innecesario (su \'unico uso en el algoritmo es representar
    aquellos nodos que no deben ser tenidos en cuenta). Con nuestras estructuras,
    y asumiendo que los candidatos ya fueron calculados, basta con quitar el nodo
    procesado del \emph{deque}/vector (cosa que si se hace en orden tiene una complejidad
    de $\mathcal O(1)$, ya que alcanca con $popear$ el elemento de uno de los extremos
    de las estructuras).

\par En segundo lugar, vemos que seg\'un avanza el algoritmo por las ramas del
    arbol de decisi\'on del \emph{backtracking}\footnote{\url{http://en.wikipedia.org/wiki/Decision_tree}}
    el tama\~no de la clique se va incrementando (m\'as espec\'ificamente, se va
    incrementando en 1 nodo por cada decisi\'on tomada), y por cada nivel (es decir,
    cliques parciales a las que se le fueron agregando 1 nodo candidato) tenemos
    un conjunto/vector/\emph{deque} de candidatos. Y dicho conjunto s\'olo es
    \'util mientras la clique en cuesti\'on tenga ramificaciones/candidatos
    que a\'un deben ser procesados. Cuando estos han sido todos procesados, el
    algoritmo realiza su fase de \emph{backtracking} quitando el \'utlimo
    nodo a\~nadido a la clique. C\'omo sabemos que no evaluaremos permutaciones
    de la misma clique (por el orden establecido para el calculo de los candidatos),
    podesmo afirmar que a lo largo de la ejecuci\'on del algoritmo tenemos
    un conjunto de candidatos por cada clique parcial o, en otras palabras,
    por cada tama\~no de clique parcial tenemos un conjunto de candidatos.

\par Ejemplificando, si tenemos la clique $\{3;5;8\}$, tendremos una conjunto
    de candidatos para $\{3\}$, otro para $\{3;5\}$ y otro para $\{3;5;8\}$.
    De esta manera, podr\'iamos guardar los candidatos de cada clique parcial
    en un vector e indexar los mismos seg\'un el tama\~no de las cliques
    parciales, teniendo a los sumo $\sfrac{n}{2}$ cliques parciales/conjuntos
    de candidatos\footnote{Secci\'on~\ref{backtracking:poda:tam_max_cmf},
    \emph{\nameref{backtracking:poda:tam_max_cmf}}}.

\par Por lo tanto, para calcular los candidatos decidimos usar un vector de
    \emph{deques} de tama\~no $\sfrac{n}{2}$.

\par A su vez, para poder llevar a cabo la poda de \emph{"M\'axima frontera de
    la rama"} de manera eficiente, utilizamos un \emph{stack}\footnote{%
    \url{http://www.cplusplus.com/reference/stack/stack/}} para poder ir
    llevando esta cota calculada sincronizada con cada clique parcial (que
    como explicamos arriba, ser\'a indexada seg\'un su tama\~no). Esto lo
    hacemos ya que esta cota depende de los candidatos a\'un v\'alidos
    de cada clique parcial, y al ir procesando cada rama de una clique
    parcial la cota ser\'a recalculada (ya que procesar una rama es
    procesar un candidato, el cual luego pasa a no pertenecer m\'as a
    los candidatos de dicha clique parcial, modificando por ende la
    cota de frontera m\'axima de la rama).

\subsubsection{Pseudoc\'odigo de complejidad}
\par Se presenta a continuaci\'on un pseudoc\'odigo m\'as espec\'ifico de la implementaci\'on
    de este algoritmo provista junto con este trabajo. El mismo tiene en cuenta
    las estructuras de datos explicadas en el punto anterior.

\par Luego del pseudoc\'odigo se justifican detalladamente las complejidades
    expuestas a continuaci\'on que no sean evidentes\footnote{Consideramos
    como "complejidades evidentes" las asignaciones de variables, operaciones
    m\'atematicas simples, asignaciones/inicializaci\'on de posiciones de
    un vector/\emph{deque} o cualquier contenedor de acceso aleatorio/arbitrario}.

\bigskip

\begin{pseudocodigo}[Algoritmo Exacto para \emph{CMF} - Complejidad]
    \Require Un grafo $G$ con $n$ v\'ertices numerados de $1$ a $n$ y $m$ aristas. El mismo
        cuenta con las siguientes estructuras de datos que lo modelan:
        \begin{itemize}
            \item Vectores de adyacencia: Dado un vertice $v$, $vecinos(v)$ nos da todos los
                nodos adyacentes a $v$ en $G$.

            \item Matriz de adyacencia: Dados los v\'ertices $v$ y $w$, $adyacentes(v,w)$ y
                $adyacentes(w,v)$ nos devuelven $true$ si y s\'olo si $v$ es adyacente
                a $w$ en $G$.

            \item Vector de nodos de $G$.
        \end{itemize}
    \Ensure\Statex
        \begin{itemize}
            \item Un vector $K$ correspondiente a la \emph{clique} de m\'axima frontera.

            \item El cardinal de $\delta(K)$, siendo $K$ la \emph{clique} del item anterior.
        \end{itemize}

    \Statex
    \If{$m = \frac{n(n-1)}{2}$} \Compl{Blue}{}{$1$}{}
        \State $K \gets \left\{1;\dots;\left\lfloor\sfrac{n}{2}\right\rfloor\right\}$ \Compl{Blue}{}{$n$}{}
        \Statex
        \State $\delta_{max} \gets \left\lfloor\sfrac{n}{2}\right\rfloor\cdot
            \left\lceil\sfrac{n}{2}\right\rceil$ \Compl{Blue}{}{$1$}{}
        \Statex

    \Else
        \State $r \gets \left\lceil\-1 + \frac{n^2}{n^2-2m}\right\rceil$ \Compl{Blue}{}{$1$}{}
        \State $\delta_{max} \gets \left\lfloor\frac{r+1}{2}\right\rfloor\cdot
            \left\lceil\frac{r+1}{2}\right\rceil$ \Compl{Blue}{}{$1$}{}
        \State $candidatos[0] \gets \{1 \dots n\}$ \Compl{Blue}{}{$n$\label{init:candidatos}}{}
        \State $solucionParcial \gets \emptyset$ \Compl{Blue}{}{$n$\label{init:solucionParcial}}{}
        \State $fronteraParcial \gets 0$ \Compl{Blue}{}{$1$}{}
        \State $pilaFrontera_{max} \gets \emptyset$ \Compl{Blue}{}{$1$\label{init:pilaFrontera_Max}}{}
        \State Ordeno por grado de mayor a menor $candidatos[0]$ \Compl{Blue}{}{$n\cdot log(n)$\label{ordenar}}{}
        \State Calculo la cota $Frontera_{max}$ para $solucionParcial$ \Compl{Blue}{}{$n$\label{init:cota_front_max}}{}
        \State $push(Frontera_{max},pilaFrontera_{max})$ \Compl{Blue}{}{$1$\label{primer_push}}{}
        \While{$candidatos[0] \neq \emptyset$ $\lor$ $solucionParcial \neq \emptyset$} \Compl{Red}{}{$1$\label{mientras}}{}
            \Statex
            \If{
                $\begin{pmatrix}
                    \text{\Huge$\bigwedge$} & 
                    \begin{matrix}
                        candidatos[|solucionParcial|] \neq \emptyset\\
                        \delta_{max} < top(pilaFrontera_{max})\\
                        |solucionParcial| < \sfrac{n}{2}
                    \end{matrix}
                \end{pmatrix}$
            } \Compl{Fuchsia}{}{$1$\label{if:rama_viva}}{}
                \Statex
                \State Muevo $cabeza(candidatos[|solucionParcial|])$ al final de $solucionParcial$ \Compl{Fuchsia}{}{$1$\label{agrego_nodo}}{}
                \State Actualizo $fronteraParcial$ \Compl{Fuchsia}{}{$1$\label{actualizo_frontera_parcial}}{}
                \State Calculamos $candidatos[|solucionParcial|]$ y $Frontera_{max}$ \Compl{Fuchsia}{}{$n-|solucionParcial|$\label{calculo_candidatos_front_max}}{}
                \State $push(Frontera_{max},pilaFrontera_{max})$ \Compl{Fuchsia}{}{$1$}{}
                \Statex
            \Else
                \If{$\delta_{max} < fronteraParcial$} \Compl{YellowOrange}{}{$1$\label{mejoro_sol}}{}
                    \State $\delta_{max} \gets fronteraParcial$ \Compl{YellowOrange}{}{$1$}{}
                    \State $K \gets solucionParcial$ \Compl{YellowOrange}{}{$|solucionParcial|$}{}
                \EndIf \Compl{Fuchsia}{Costo \emph{si}: }{$|solucionParcial|$}{}%
                \State Vac\'io $candidatos[|solucionParcial|]$ \Compl{Fuchsia}{}{$n-|solucionParcial|$\label{backtracking_init}}{}
                \If{$solucionParcial \neq \emptyset$} \Compl{YellowOrange}{}{$1$}{}
                    \State $pop(pilaFrontera_{max})$ \Compl{YellowOrange}{}{$1$}{}
                    \State Elimino a $ultimo(solucionParcial)$ \Compl{YellowOrange}{}{$1$}{}
                    \State Recalculo $fronteraParcial$ \Compl{YellowOrange}{}{$1$}{}
                    \State Recalculo $Frontera_{max}$ \Compl{YellowOrange}{}{$n-|solucionParcial|$}{}
                    \State $push(Frontera_{max},pilaFrontera_{max})$ \Compl{YellowOrange}{}{$1$}{}
                \EndIf \Compl{Fuchsia}{Costo \emph{si}: }{$n-|solucionParcial|$\label{backtracking_end}}{}
            \EndIf \Compl{Red}{Costo \emph{si}: }{$n$\label{backtracking_if}}{}
        \EndWhile \Compl{Blue}{Costo \emph{mientras}: }{$2^n$}{veces $\times$ $\mathcal O(n) = \mathcal O(n\cdot 2^n)$\label{costo_ciclo} }
    \EndIf \Compl{Brown}{Costo \emph{si}: }{$n + n\cdot log(n) + n\cdot 2^n$}{$= \mathcal O(n\cdot 2^n)$ }%

    \State \Return{$\delta_{max}$, $K$} \Compl{Brown}{}{$1$\label{backtracking:return}}{}%
    \Statex
    \Statex \Compl{Brown}{Costo Total de Algoritmo: }{$n\cdot 2^n$}{}
\end{pseudocodigo}

\bigskip

\par Inicialmente, en las l\'ineas~\ref{init:candidatos} y~\ref{init:solucionParcial} ,
    se ve como se inicializan ciertos vectores: $solucionParcial$ (representa una clique),
    $candidatos$ (ser\'a el vector que contendr\'a a los \emph{deques} de candidatos
    de cada clique parcial). El costo de estos es $\mathcal O(n)$ ya que si bien
    inicializar un vector tiene costo constante\footnote{\url{http://www.cplusplus.com/reference/vector/vector/vector/}}
    , queremos evitar el costo amortizado que tienen las inserciones en el mismo. Como
    se sabe de antemano cual es la m\'axima cantidad de cliques parciales que pueden llegar
    a haber\footnote{Secci\'on~\ref{backtracking:poda:tam_max_cmf},
    \emph{\nameref{backtracking:poda:tam_max_cmf}}},
    utilizamos el m\'etodo \emph{reserve}\footnote{\url{%
    http://www.cplusplus.com/reference/vector/vector/reserve/}} para reservarnos
    $\sfrac{n}{2}$ posiciones de memoria. Por lo tanto, el costo de estas operaciones
    es $\mathcal O(\sfrac{n}{2}) = \mathcal O(n)$. A su vez, en el caso de $candidatos$,
    tambi\'en se inicializa su primer posici\'on (que es un \emph{deque}), en esta
    se colocan todos los nodos del grafo $G$ de entrada. El coste de inicializar
    un \emph{deque} de esta manera es lineal\footnote{\url{%
    http://www.cplusplus.com/reference/deque/deque/push_back/}, \url{%
    http://www.cplusplus.com/reference/algorithm/generate_n/} y \url{%
    http://www.cplusplus.com/reference/iterator/back_inserter/}}, con lo cual la complejidad
    sigue manteni\'endose lineal.

\par En la l\'inea~\ref{init:pilaFrontera_Max} se ve como se inicializa un \emph{stack},
    siendo su costo $\mathcal O(1)$ seg\'un lo asegura la documentaci\'on de la \emph{STL}
    de \emph{C++}\footnote{\url{http://www.cplusplus.com/reference/stack/stack/stack/} y
    \url{http://www.cplusplus.com/reference/deque/deque/deque/}}.

\par Continuando, luego de inicializar los valores se pasa a ordenar los $candidatos$
    iniciales de mayor a menor seg\'un su grado en $G$ (l\'inea~\ref{ordenar}).
    El coste de este es $\mathcal O(n \cdot log(n))$ pues la estructura sobre la que
    se trabaja es un \emph{deque} que cuenta con iteradores de acceso aleatorio\footnote{%
    \url{http://www.cplusplus.com/reference/algorithm/sort/}} y el acceso a este
    \emph{deque} se realiza en tiempo constante pues es una acceso indizado en
    el vector $candidatos$.

\par En el paso siguiente (l\'inea~\ref{init:cota_front_max}) pasamos a calcular
    la cota de frontera m\'axima de la rama para una clique parcial que a\'un
    no tiene ning\'un elemento (es decir, es vac\'ia). Esto se realiza siguiendo
    los pasos enumerados en la Secci\'on~\ref{backtracking:poda:cota_frontera_max}
    (\emph{\nameref{backtracking:poda:cota_frontera_max}}) y aprovechando que los
    $candidatos[0]$ est\'an ya ordenados. Por lo tanto, esta operatoria
    debe recorrer los candidatos en orden y calcular la cota seg\'un sus
    grados como se coment\'o en la Secci\'on~\ref{orden_establecido}. Como
    el grafo instanciado cuenta con un vector de punteros a \emph{nodo}, y este
    nos da acceso en tiempo constante a su grado, acceder al grado de un nodo
    en los $candidatos[0]$ pasa a ser tiempo constante, y en el peor de los
    casos se deben recorrer los primeros $\sfrac{n}{2}$ nodos de $candidatos[0]$%
    \footnote{Secci\'on~\ref{backtracking:poda:tam_max_cmf}, \emph{\nameref{backtracking:poda:tam_max_cmf}}},
    d\'andonos un total de hasta $\sfrac{n}{2}$ operaciones $\mathcal O(1)$. Entonces
    el costo final pasa a ser $\mathcal O(n)$.

\par A continuaci\'on, en la l\'inea~\ref{primer_push}, se inserta el primer elemento
    en $pilaFrontera_{max}$, cuyo costo es constante ya que su estructura interna
    es un \emph{stack} que utiliza un \emph{deque} como contenedor\footnote{\url{%
    http://www.cplusplus.com/reference/stack/stack/push/} y \url{http://www.cplusplus.com/reference/deque/deque/push_back/}}.

\par En la l\'inea~\ref{if:rama_viva} tenemos por un lado el coste de acceder
    a una posici\'on del vector $candidatos$\footnote{\url{%
    http://www.cplusplus.com/reference/vector/vector/operator[]/}}, el coste
    de obtener el tama\~no del vector $solucionParcial$\footnote{\url{%
    http://www.cplusplus.com/reference/vector/vector/size/}} y el coste
    de acceder al tope de la pila $pilaFrontera_{max}$\footnote{\url{%
    http://www.cplusplus.com/reference/stack/stack/top/}}. Todos estos
    tienen una complejidad constante y son utilizados en 3 operaciones de comparaci\'on,
    que tambi\'en son de costo constante y al estar acotadas por 3 podemos concluir
    que el coste de toda la operaci\'on es $\mathcal O(1)$.

\par Siguiendo, en la l\'inea~\ref{agrego_nodo} se pasa un elemento de los $candidatos[|solucionParcial|]$
    a la clique/vector $solucionParcial$. Esta operaci\'on consiste
    en consultar el tama\~no del vector $solucionParcial$, un acceso
    indizado a $candidatos$ (ambas operaciones que ya se han hecho y se a explicado
    porque tienen costo constante), un $push_back$ al vector $solucionParcial$
    \footnote{\url{http://www.cplusplus.com/reference/vector/vector/push_back/}} y
    un $pop_front$ del \emph{deque} $candidatos[|solucionParcial|]$\footnote{\url{%
    http://www.cplusplus.com/reference/deque/deque/pop_front/}}. Estas \'ultimas
    2 operaciones tambi\'en tiene costo constante, obteni\'endose entonces
    un costo total para la operaci\'on de $\mathcal O(1)$.

\par En el paso siguiente, en la l\'inea~\ref{actualizo_frontera_parcial}
    expresamos que al agregar un nuevo nodo a la clique $solucionParcial$,
    calcular su frontera tiene coste $\mathcal O(1)$. Esto es as\'i pues
    ya teniendo el valor de la $fronteraParcial$ para la clique sin este
    nuevo nodo, basta con acceder al grado del v\'ertice recientemente
    agregado (se puede hacer en tiempo constante como ya se a explicado)
    y considerar las aristas que le suma a la $fronteraParcial$ que ya
    se ten\'ia. Esto se puede hacer con la siguiente f\'ormula matem\'atica:

\bigskip

\par $\delta(K+v) = \delta(K) - |K| + d(v) - |K| = \delta(K) + d(v) - 2|K|$.

\bigskip

\par Esta f\'ormula nos dice que agregar un nodo candidato $v$ a una clique $K$
    nos resta $|K|$ aristas de la frontera (las que se utilizan para agregar
    a $v$) y nos suma $d(v) - |K|$ ($|K|$ aristas de $v$ utilizadas para agregarse
    a $K$). Esta operaci\'on matem\'atica tiene coste $\mathcal O(1)$, por lo cual
    el costo final de recalcular la $fronteraParcial$ de nuestra $solucionParcial$
    a la que se le agreg\'o un nodo candidato es tambi\'en $\mathcal O(1)$.

\par En este proceso de agregado de nodos a la clique parcial, tambi\'en debemos
    calcular los candidatos de la nueva $solucionParcial$ (que ahora tiene otro
    nodo). En la l\'inea~\ref{calculo_candidatos_front_max} hacemos esto. Su coste
    es l\'ineal en la cantidad de nodos que no forman parte de la clique parcial,
    ya que lo que se hace es recorrer los nodos candidatos de la $solucionParcial$
    antes de agregarle un nodo, y verificar cuales de ellos son adyacentes tambi\'en
    a el nuevo nodo. Aqu\'i se requiere un acceso indizado al vector $candidatos$
    a la posici\'on $|solucionParcial|-1$ (donde pedirle el tama\~no al vector
    $solucionParcial$ tiene costo constante como ya se a explicado) cuya complejidad
    es $\mathcal O(1)$ como ya se ha visto. Por lo tanto, el coste pasa a ser el de
    recorrer los $candidatos[|solucionParcial|-1]$ (que por ser un \emph{deque} tiene
    costo lineal en la cantidad de elementos)y realizar una operaci\'on
    $\mathcal O(1)$ sobre la matriz de adyacencia de $G$. Por lo tanto, en el peor
    de los casos, la cantidad de nodos candidatos que se recorren son $n - |solucionParcial|$
    (ya que los nodos de la clique parcial seguro no estar\'an en los nodos candidatos),
    quedando as\'i una complejidad de $\mathcal O(n - |solucionParcial|)$.

\par En esta \'ultima l\'inea tambi\'en se calcula la cota de la frontera m\'axima
    por rama. Como ya se explic\'o, el costo de este se calcula recorriendo los
    candidatos de la soluci\'on parcial (que ya fueron calculados), y como ya vimos,
    estos estar\'an acotados por $n - |solucionParcial|$, quedando la complejidad
    final de la l\'inea~\ref{calculo_candidatos_front_max} en $\mathcal O(2\cdot
    n - |solucionParcial|) = \mathcal O(n - |solucionParcial|)$.

\par En el \emph{si} de la l\'inea~\ref{mejoro_sol} tenemos un costo final de
    $\mathcal O(|solucionParcial|)$. Esto se debe a que al llegar al final de una
    rama (ya sea porque fue "podada" o porque no quedan m\'as candidatos), se verifica
    si se mejor\'o la mejor soluci\'on constru\'ida hasta el momento. En caso de ser
    as\'i, se guarda la clique $solucionParcial$ en otro vector llamado $K$. Esto tiene
    un costo lineal en la cantidad de elementos copiados\footnote{\url{%
    http://www.cplusplus.com/reference/vector/vector/operator=/}}.

\par Finalizando el ciclo \emph{mientras}, entre las l\'ineas~\ref{backtracking_init} y%
    ~\ref{backtracking_end}, se\~nalamos un coste total $\mathcal O(n -|solucionParcial|)$.
    En la primera operaci\'on nos encargamos de limpiar los candidatos de la clique
    parcial actual (simplemente hacemos esto porque al calcular los candidatos
    utilizamos las operaciones $push_back$, con lo cual al haber terminado con una rama,
    queremos dejar el \emph{deque} vac\'io para no tener clientes de ramas
    anteriores). Esta operaci\'on tiene un costo lineal en la cantidad de destrucciones%
    \footnote{\url{http://www.cplusplus.com/reference/deque/deque/clear/}}. El resto
    de las operaciones son todas de tiempo constante (y ya sin necesidad de explicar
    mucho habiendo ya justificado operaciones similares).

\par Ya terminando, tenemos que como coste final del \emph{si} que est\'a dentro
    del ciclo principal del bucle (l\'inea~\ref{backtracking_if}), tenemos un
    coste $\mathcal O(n)$ ya que tomamos el m\'aximo de los costos de ambas
    ramas del condicional: $\mathcal O(n-|solucionParcial|)$ por la bifurcaci\'on
    positiva y $\mathcal O(n-|solucionParcial|) + \mathcal O(|solucionParcial|) =
    \mathcal O(n)$. Por lo tanto, nos queda $\mathcal O(n)$ que es claramente
    mayor que $\mathcal O(n-|solucionParcial|)$.

\par Por \'ultimo, llegando a la parte m\'as compleja de justificar, debemos
    acotar la cantidad de iteraciones que hara el ciclo \emph{mientras} de la
    l\'inea~\ref{mientras}. Esto lo haremos bas\'andonos en el \'arbol de
    decisiones que sigue nuestro algoritmo.

\par Como ya se explico en la secci\'on~\ref{backtracking:explicacion}, nuestro
    algoritmo va construyendo cliques contenidas en el grafo $G$. Es decir, en cada
    instancia de decisi\'on, el algoritmo agrega un nodo a la clique parcial que va
    construyendo, y continua haciendo esto hasta pasar por todas las posbiles
    cliques de $G$. Si bien no es estrictamente cierto que se pasen por todas las cliques,
    ya que alguna de las podas implementadas podr\'ia evitarlo,
    como estamos buscando una cota para la m\'axima cantidad de iteraciones
    del ciclo, se puede suponer que en el peor de los casos tenemos una instancia
    de un grafo $G$ que "anula" estas podas (en el sentido que tiene una estructura
    que no permiten que las podas act\'uen, por ejemplo podr\'iamos tener un $G$ en
    que cada clique parcial constru\'ida sea de menor frontera que la siguiente,
    obligando al algoritmo a construir todas las cliques de $G$).

\par Ahora bien, en este \'arbol de decisiones podemos pensar que en el primer nodo
    tenemos una bifurcaci\'on: inclu\'imos al primer nodo en la clique parcial o
    no lo hacemos. Luego, en cada bifurcaci\'on se nos presentar\'a la misma
    diyuntiva para con el siguiente nodo. Y as\'i sucesivamente. Es decir, el
    \'arbol de decisiones es un \'arbol binario perfecto (en el peor caso) de
    altura $n$. Por lo tanto, la cantidad total de nodos que tendr\'a
    (contando nodos internos tanto como hojas) es%
    \footnote{\url{http://www.brpreiss.com/books/opus5/html/page257.html}}:
    $2^{n+1}-1$

\bigskip
\par Entonces, habiendo calculado ya una cota para la m\'axima cantidad de iteraciones
    del ciclo, s\'olo nos queda considerar el costo de cada iteraci\'on (que ya
    lo hemos calculado) multiplicada por esta cota (l\'inea~\ref{costo_ciclo}).

\par El siguiente gr\'afico ilustra el \'arbol de decisiones del que estamos hablando,
    incluyendo los costos de las iteraciones de los ciclos.

\begin{figure}[H]
    \centering
    \caption{\'Arbol de Decisiones del Algoritmo Exacto}
    \begin{tikzpicture}[
        level 1/.style={sibling distance=80mm,level distance=40mm},
        level 2/.style={sibling distance=40mm},
    ]
        % the tree
        \node (r1) {$n$ nodos restantes}
        child {node (l2) {$n-1$ nodos restantes}
            child{edge from parent node[sloped,anchor=south]{Agregar Nodo}}
            child{edge from parent node[sloped,anchor=south]{No Agregar Nodo}}
            edge from parent node[sloped,anchor=south]{Agregar Nodo}
        }
        child {node (r2) {$n-1$ nodos restantes}
            child{edge from parent node[sloped,anchor=south]{Agregar Nodo}}
            child{edge from parent node[sloped,anchor=south]{No Agregar Nodo}}
            edge from parent node[sloped,anchor=south]{No Agregar Nodo}
        };
        % the last line of thetas
        \node[anchor=north,inner sep=0pt] (theta) at ([yshift=-4cm,xshift=4.0cm]l2){%
            $\dotstheta$\hspace{32mm}$\dotstheta$\hspace{32mm}$\dotstheta$\hspace{32mm}$\dotstheta$};

        % two auxiliary coordinates
        \coordinate (aux1) at ( $ (r1) + (8,0) $ );
        \coordinate (aux2) at ( $ (r1) + (-8,0) $ );

        % the nodes to the right of the tree
        \node(t1) at (aux1) {$1 \times \mathcal O(n)$};
        \node(t2) at (r2-|aux1) {$2 \times\mathcal O(n)$};

        % arrows from the tree to the nodes on the right
        \foreach \i in {1,2}
            \draw[->,line width=1pt,dashed] (r\i) -- (t\i);

        % the arrow to the left of the tree
        \draw[<->] (aux2) -- node[fill=white] {$n$} (aux2|-theta.184);

        % the brace at the bottom
        \draw[decorate,decoration={brace,raise=2pt}] (theta.south east) -- node[label={[label distance=5pt]below:$2^{n} \times \mathcal O(n)$}]{}  (theta.south west);

        % the rule with the total
        \node[below = 7cm of t2.east,anchor=east] {Complejidad Total del Ciclo: $\mathcal O\Biggl(\displaystyle\sum_{k=0}^{n} 2^k \cdot n\Biggl) = \mathcal O\Biggl(n \cdot \sum_{k=0}^{n} 2^k\Biggl) = \mathcal O\Bigl(n \cdot 2^{n}\Bigl)$};
    \end{tikzpicture}
\end{figure}
\bigskip

\par Por \'ultimo, en la l\'inea~\ref{backtracking:return} el coste es
    $\mathcal O(1)$ ya que $\delta_{max}$ es un tipo primitivo del lenguaje (un
    entero) y la clique/vector $K$ se devuelve por referencia (otro tipo primitivo
    -puntero- de \emph{C++}).

\par\hfill

\par As\'i pues, llegamos a la conclusi\'on de que la complejidad asint\'otica
    temporal de nuestro algoritmo exacto es $\mathcal O(n \cdot 2^{n})$.
